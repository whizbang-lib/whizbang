#region HEADER
// <auto-generated/>
// Generated at: __TIMESTAMP__
#endregion
#nullable enable

using System;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.EntityFrameworkCore;
using Microsoft.Extensions.Logging;
using Whizbang.Data.Postgres.Schema;
using Whizbang.Data.Schema;

namespace __DBCONTEXT_NAMESPACE__.Generated;

/// <summary>
/// Extension methods for __DBCONTEXT_CLASS__ schema initialization.
/// AOT-compatible - uses PostgresSchemaBuilder instead of EF Core's GenerateCreateScript().
/// </summary>
public static class __DBCONTEXT_CLASS__SchemaExtensions {
  /// <summary>
  /// Ensures Whizbang database schema is fully initialized for __DBCONTEXT_CLASS__.
  /// Creates core infrastructure tables, perspective tables, executes migrations, and adds constraints.
  /// Idempotent - safe to call multiple times.
  /// AOT-compatible - no reflection, no dynamic code generation.
  ///
  /// Steps:
  /// 1. Creates core infrastructure tables (Inbox, Outbox, EventStore, etc.) - generated at runtime from C# definitions
  /// 2. Creates perspective tables (PerspectiveRow&lt;TModel&gt; tables) - generated at build time from discovered types
  /// 3. Adds composite PK and FK constraints
  /// 4. Executes PostgreSQL migrations (creates functions like process_work_batch)
  /// </summary>
  /// <param name="dbContext">The __DBCONTEXT_CLASS__ instance</param>
  /// <param name="logger">Optional logger for diagnostic messages</param>
  /// <param name="cancellationToken">Cancellation token</param>
  public static async Task EnsureWhizbangDatabaseInitializedAsync(
    this __DBCONTEXT_FQN__ dbContext,
    ILogger? logger = null,
    CancellationToken cancellationToken = default) {

    // Step 1: Create core infrastructure tables (Inbox, Outbox, EventStore, etc.)
    logger?.LogInformation("Creating core infrastructure tables for {DbContext}...", "__DBCONTEXT_CLASS__");
    await ExecuteCoreInfrastructureTablesAsync(dbContext, logger, cancellationToken);

    // Step 2: Create perspective tables (generated at build time from discovered PerspectiveRow<TModel> types)
    logger?.LogInformation("Creating perspective tables for {DbContext}...", "__DBCONTEXT_CLASS__");
    await ExecutePerspectiveTablesAsync(dbContext, logger, cancellationToken);

    // Step 3: Add constraints (composite PKs, FKs) that TableDefinition doesn't support yet
    logger?.LogInformation("Adding database constraints for {DbContext}...", "__DBCONTEXT_CLASS__");
    await ExecuteConstraintsAsync(dbContext, logger, cancellationToken);

    // Step 4: Create PostgreSQL functions (process_work_batch, etc.)
    logger?.LogInformation("Creating PostgreSQL functions for {DbContext}...", "__DBCONTEXT_CLASS__");
    await ExecuteMigrationsAsync(dbContext, logger, cancellationToken);

    logger?.LogInformation("Whizbang database initialization complete for {DbContext}", "__DBCONTEXT_CLASS__");
  }

  /// <summary>
  /// Executes core infrastructure table DDL at runtime.
  /// Creates all Whizbang core tables: Inbox, Outbox, EventStore, ReceptorProcessing,
  /// PerspectiveCheckpoints, RequestResponse, ServiceInstances, PartitionAssignments,
  /// MessageDeduplication, Sequences, and EventSequence.
  /// SQL is generated at runtime using PostgresSchemaBuilder.Instance.BuildInfrastructureSchema().
  /// AOT-compatible - no reflection or dynamic code generation, just string building.
  /// </summary>
  private static async Task ExecuteCoreInfrastructureTablesAsync(
    __DBCONTEXT_FQN__ dbContext,
    ILogger? logger,
    CancellationToken cancellationToken) {

    // Generate schema SQL at runtime from C# definitions
    var schemaConfig = new SchemaConfiguration(
      InfrastructurePrefix: "wh_",
      PerspectivePrefix: "wh_per_",
      SchemaName: "__SCHEMA__"
    );
    var coreInfrastructureSchema = PostgresSchemaBuilder.Instance.BuildInfrastructureSchema(schemaConfig);

    // DIAGNOSTIC: Log whether message_associations table is in the generated SQL
    if (coreInfrastructureSchema.Contains("wh_message_associations")) {
      logger?.LogInformation("DIAGNOSTIC: wh_message_associations table SQL is present in schema");

      // CRITICAL: Check if it's schema-qualified correctly
      var expectedTable = string.IsNullOrEmpty("__SCHEMA__") || "__SCHEMA__" == "public"
        ? "wh_message_associations"
        : "__SCHEMA__.wh_message_associations";
      if (coreInfrastructureSchema.Contains(expectedTable)) {
        logger?.LogInformation("DIAGNOSTIC: Table is correctly schema-qualified as '{Table}'", expectedTable);
      } else {
        logger?.LogError("DIAGNOSTIC: Table is NOT schema-qualified! Expected '{Expected}' but SQL contains unqualified 'wh_message_associations'", expectedTable);
      }
    } else {
      logger?.LogWarning("DIAGNOSTIC: wh_message_associations table SQL is MISSING from schema!");
    }

    try {
      await dbContext.Database.ExecuteSqlRawAsync(coreInfrastructureSchema, cancellationToken);
      logger?.LogInformation("Core infrastructure tables created successfully");
    } catch (Npgsql.PostgresException ex) when (ex.SqlState == "42P07") {
      // 42P07 = duplicate_table (expected if tables already exist)
      logger?.LogInformation("Core infrastructure tables already exist (expected): {Table}", ex.TableName ?? "unknown");
    } catch (Exception ex) {
      logger?.LogError(ex, "Failed to create core infrastructure tables");
      throw;
    }
  }

  /// <summary>
  /// Executes perspective table DDL generated at build time.
  /// SQL is generated by discovering PerspectiveRow&lt;TModel&gt; types in user code.
  /// Creates tables with schema: stream_id (UUID PK), data (JSONB), version (BIGINT), updated_at (TIMESTAMPTZ).
  /// AOT-compatible - no reflection or dynamic code generation.
  /// </summary>
  private static async Task ExecutePerspectiveTablesAsync(
    __DBCONTEXT_FQN__ dbContext,
    ILogger? logger,
    CancellationToken cancellationToken) {

    // SQL embedded by source generator from discovered PerspectiveRow<TModel> types
    const string PerspectiveTablesSchema = #region PERSPECTIVE_TABLES_SCHEMA
    // Perspective table DDL will be embedded here by the source generator
    #endregion;

    if (string.IsNullOrWhiteSpace(PerspectiveTablesSchema)) {
      logger?.LogInformation("No perspective tables to create (DbContext has no perspectives)");
      return;
    }

    try {
      await dbContext.Database.ExecuteSqlRawAsync(PerspectiveTablesSchema, cancellationToken);
      logger?.LogInformation("Perspective tables created successfully");
    } catch (Npgsql.PostgresException ex) when (ex.SqlState == "42P07") {
      // 42P07 = duplicate_table (expected if tables already exist)
      logger?.LogInformation("Perspective tables already exist (expected): {Table}", ex.TableName ?? "unknown");
    } catch (Exception ex) {
      logger?.LogError(ex, "Failed to create perspective tables");
      throw;
    }
  }

  /// <summary>
  /// Executes constraint DDL for composite primary keys and foreign keys.
  /// These constraints are not yet supported in TableDefinition, so they're added manually.
  /// Includes: composite PK for perspective_checkpoints, FKs to event_store, unique constraints.
  /// </summary>
  private static async Task ExecuteConstraintsAsync(
    __DBCONTEXT_FQN__ dbContext,
    ILogger? logger,
    CancellationToken cancellationToken) {

    const string Constraints = @"
-- Foreign keys (note: PostgreSQL doesn't support IF NOT EXISTS for FK constraints)
DO $$
BEGIN
  -- FK: receptor_processing.event_id -> event_store.event_id
  IF NOT EXISTS (
    SELECT 1 FROM pg_constraint WHERE conname = 'fk_receptor_processing_event'
  ) THEN
    ALTER TABLE __SCHEMA__.wh_receptor_processing
      ADD CONSTRAINT fk_receptor_processing_event
      FOREIGN KEY (event_id) REFERENCES __SCHEMA__.wh_event_store(event_id) ON DELETE CASCADE;
  END IF;

  -- FK: perspective_checkpoints.last_event_id -> event_store.event_id
  IF NOT EXISTS (
    SELECT 1 FROM pg_constraint WHERE conname = 'fk_perspective_checkpoints_event'
  ) THEN
    ALTER TABLE __SCHEMA__.wh_perspective_checkpoints
      ADD CONSTRAINT fk_perspective_checkpoints_event
      FOREIGN KEY (last_event_id) REFERENCES __SCHEMA__.wh_event_store(event_id) ON DELETE RESTRICT;
  END IF;
END $$;

-- Unique constraint for receptor_processing (event_id, receptor_name)
CREATE UNIQUE INDEX IF NOT EXISTS uq_receptor_processing_event_receptor
  ON __SCHEMA__.wh_receptor_processing(event_id, receptor_name);

-- Partial indexes for status-based queries
CREATE INDEX IF NOT EXISTS idx_receptor_processing_status_failed
  ON __SCHEMA__.wh_receptor_processing(status) WHERE (status & 4) = 4; -- Failed flag

CREATE INDEX IF NOT EXISTS idx_perspective_checkpoints_catching_up
  ON __SCHEMA__.wh_perspective_checkpoints(status) WHERE (status & 8) = 8; -- CatchingUp flag

CREATE INDEX IF NOT EXISTS idx_perspective_checkpoints_failed
  ON __SCHEMA__.wh_perspective_checkpoints(status) WHERE (status & 4) = 4; -- Failed flag
";

    try {
      await dbContext.Database.ExecuteSqlRawAsync(Constraints, cancellationToken);
      logger?.LogInformation("Database constraints added successfully");
    } catch (Npgsql.PostgresException ex) {
      // Constraints might already exist - log as information, not error
      logger?.LogInformation("Constraint operation completed (some constraints may already exist): {Message}", ex.MessageText);
    } catch (Exception ex) {
      logger?.LogWarning(ex, "Failed to add some database constraints (constraints may already exist)");
      // Don't throw - constraints might already exist from previous runs
    }
  }

  /// <summary>
  /// Executes PostgreSQL migration scripts to create functions.
  /// Migrations are embedded as string constants for AOT compatibility.
  /// </summary>
  private static async Task ExecuteMigrationsAsync(
    __DBCONTEXT_FQN__ dbContext,
    ILogger? logger,
    CancellationToken cancellationToken) {

    // Migration scripts are embedded below by the source generator
    var migrations = GetMigrationScripts();

    foreach (var (name, sql) in migrations) {
      try {
        logger?.LogInformation("Executing migration: {Migration}", name);

        // Transform migration SQL to include schema qualification
        // Replace all unqualified table names (e.g., "wh_inbox", "wh_outbox") with schema-qualified names (e.g., "inventory.wh_inbox")
        var transformedSql = _transformMigrationSql(sql, "__SCHEMA__");

        // DIAGNOSTIC: Log sample of transformed SQL to verify schema qualification
        if (name.Contains("ProcessWorkBatch") || name.Contains("process_work_batch")) {
          var sampleLines = string.Join("\n", transformedSql.Split('\n').Take(50));
          logger?.LogInformation("DIAGNOSTIC: Sample of transformed SQL for {Migration}:\n{Sample}", name, sampleLines);

          // Check if transformation worked
          if (!string.IsNullOrEmpty("__SCHEMA__") && "__SCHEMA__" != "public") {
            var hasQualified = transformedSql.Contains("__SCHEMA__.wh_outbox") || transformedSql.Contains("__SCHEMA__.wh_inbox");
            var hasUnqualified = System.Text.RegularExpressions.Regex.IsMatch(transformedSql, @"(?<!\.)(\bwh_outbox\b|\bwh_inbox\b)");
            logger?.LogInformation("DIAGNOSTIC: Transformation check - HasQualified={HasQualified}, HasUnqualified={HasUnqualified}",
              hasQualified, hasUnqualified);
          }
        }

        await dbContext.Database.ExecuteSqlRawAsync(transformedSql, cancellationToken);
        logger?.LogInformation("Migration {Migration} completed successfully", name);
      } catch (Npgsql.PostgresException ex) when (ex.SqlState == "42723") {
        // 42723 = duplicate_function - function already exists, safe to ignore
        logger?.LogInformation("Function already exists (expected): {Message}", ex.MessageText);
      } catch (Exception ex) {
        logger?.LogError(ex, "Failed to execute migration {Migration}", name);
        throw;
      }
    }
  }

  /// <summary>
  /// Returns migration scripts as (name, sql) tuples.
  /// Scripts are embedded by the source generator.
  /// </summary>
  private static (string Name, string Sql)[] GetMigrationScripts() {
    return new[] {
      #region MIGRATIONS
      // Migration scripts will be embedded here by the source generator
      #endregion
    };
  }

  /// <summary>
  /// Transforms migration SQL to include schema qualification for all Whizbang infrastructure tables.
  /// Replaces patterns like "wh_inbox", "wh_outbox", etc. with "schema.wh_inbox", "schema.wh_outbox".
  /// Uses word boundaries to avoid replacing partial matches (e.g., won't replace "wh_inbox_id" column names).
  /// </summary>
  /// <param name="sql">Original migration SQL</param>
  /// <param name="schema">Schema name to prepend (e.g., "inventory", "bff")</param>
  /// <returns>Transformed SQL with schema-qualified table names</returns>
  private static string _transformMigrationSql(string sql, string schema) {
    // If schema is empty or "public", return SQL unchanged
    if (string.IsNullOrEmpty(schema) || schema == "public") {
      return sql;
    }

    // List of Whizbang infrastructure table names to qualify
    var tableNames = new[] {
      "wh_inbox",
      "wh_outbox",
      "wh_event_store",
      "wh_events", // Alias for wh_event_store
      "wh_receptor_processing",
      "wh_perspective_checkpoints",
      "wh_perspective_events",
      "wh_message_associations",
      "wh_request_response",
      "wh_service_instances",
      "wh_partition_assignments",
      "wh_message_deduplication",
      "wh_sequences",
      "wh_active_streams",
      "wh_event_sequence" // Sequence name
    };

    var transformedSql = sql;

    // Replace each table name with schema-qualified version
    // Use word boundaries (\b) to avoid replacing column names or partial matches
    foreach (var tableName in tableNames) {
      // Pattern: tableName NOT preceded by period (to avoid replacing already-qualified names)
      // Matches: "FROM wh_inbox", "ALTER TABLE wh_inbox", etc.
      // Does NOT match: "inventory.wh_inbox", "wh_inbox_id" (column name)
      transformedSql = System.Text.RegularExpressions.Regex.Replace(
        transformedSql,
        $@"(?<!\.)(\b{System.Text.RegularExpressions.Regex.Escape(tableName)}\b)",
        $"{schema}.$1",
        System.Text.RegularExpressions.RegexOptions.IgnoreCase
      );
    }

    // List of Whizbang PostgreSQL function names to qualify
    // CRITICAL: Functions are database-wide in PostgreSQL. When multiple schemas share the same database,
    // they must have schema-qualified function names to avoid overwriting each other's functions.
    var functionNames = new[] {
      "register_message_associations",
      "process_work_batch",
      "process_inbox_batch",
      "process_outbox_batch",
      "process_perspectives_batch"
    };

    // Replace function names in CREATE/DROP/CALL statements
    // This ensures each schema has its own function instance (e.g., inventory.register_message_associations)
    foreach (var functionName in functionNames) {
      // Pattern 1: "CREATE [OR REPLACE] FUNCTION functionName(" → "CREATE [OR REPLACE] FUNCTION schema.functionName("
      transformedSql = System.Text.RegularExpressions.Regex.Replace(
        transformedSql,
        $@"(CREATE\s+(?:OR\s+REPLACE\s+)?FUNCTION\s+)(?<!\.)\b{System.Text.RegularExpressions.Regex.Escape(functionName)}\b(\s*\()",
        $"$1{schema}.{functionName}$2",
        System.Text.RegularExpressions.RegexOptions.IgnoreCase
      );

      // Pattern 2: "DROP FUNCTION [IF EXISTS] functionName" → "DROP FUNCTION [IF EXISTS] schema.functionName"
      transformedSql = System.Text.RegularExpressions.Regex.Replace(
        transformedSql,
        $@"(DROP\s+FUNCTION\s+(?:IF\s+EXISTS\s+)?)(?<!\.)\b{System.Text.RegularExpressions.Regex.Escape(functionName)}\b",
        $"$1{schema}.{functionName}",
        System.Text.RegularExpressions.RegexOptions.IgnoreCase
      );

      // Pattern 3: "GRANT ... ON FUNCTION functionName" → "GRANT ... ON FUNCTION schema.functionName"
      // This handles GRANT/REVOKE statements for function permissions
      transformedSql = System.Text.RegularExpressions.Regex.Replace(
        transformedSql,
        $@"((?:GRANT|REVOKE)\s+.*\s+ON\s+FUNCTION\s+)(?<!\.)\b{System.Text.RegularExpressions.Regex.Escape(functionName)}\b",
        $"$1{schema}.{functionName}",
        System.Text.RegularExpressions.RegexOptions.IgnoreCase
      );

      // Pattern 4: "COMMENT ON FUNCTION functionName" → "COMMENT ON FUNCTION schema.functionName"
      // This handles COMMENT statements for function documentation
      transformedSql = System.Text.RegularExpressions.Regex.Replace(
        transformedSql,
        $@"(COMMENT\s+ON\s+FUNCTION\s+)(?<!\.)\b{System.Text.RegularExpressions.Regex.Escape(functionName)}\b",
        $"$1{schema}.{functionName}",
        System.Text.RegularExpressions.RegexOptions.IgnoreCase
      );
    }

    return transformedSql;
  }

}
