#region HEADER
// <auto-generated/>
// Generated at: __TIMESTAMP__
#endregion
#nullable enable

using System;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.EntityFrameworkCore;
using Microsoft.Extensions.Logging;

namespace __DBCONTEXT_NAMESPACE__.Generated;

/// <summary>
/// Extension methods for __DBCONTEXT_CLASS__ schema initialization.
/// AOT-compatible - uses pre-generated SQL instead of EF Core's GenerateCreateScript().
/// </summary>
public static class __DBCONTEXT_CLASS__SchemaExtensions {
  /// <summary>
  /// Ensures Whizbang database schema is fully initialized for __DBCONTEXT_CLASS__.
  /// Creates core infrastructure tables, perspective tables, executes migrations, and adds constraints.
  /// Idempotent - safe to call multiple times.
  /// AOT-compatible - all SQL is pre-generated at build time.
  ///
  /// Steps:
  /// 1. Creates core infrastructure tables (Inbox, Outbox, EventStore, etc.)
  /// 2. Creates perspective tables (PerspectiveRow&lt;TModel&gt; tables)
  /// 3. Adds composite PK and FK constraints
  /// 4. Executes PostgreSQL migrations (creates functions like process_work_batch)
  /// </summary>
  /// <param name="dbContext">The __DBCONTEXT_CLASS__ instance</param>
  /// <param name="logger">Optional logger for diagnostic messages</param>
  /// <param name="cancellationToken">Cancellation token</param>
  public static async Task EnsureWhizbangDatabaseInitializedAsync(
    this __DBCONTEXT_FQN__ dbContext,
    ILogger? logger = null,
    CancellationToken cancellationToken = default) {

    // Step 1: Create core infrastructure tables (Inbox, Outbox, EventStore, etc.)
    logger?.LogInformation("Creating core infrastructure tables for {DbContext}...", "__DBCONTEXT_CLASS__");
    await ExecuteCoreInfrastructureTablesAsync(dbContext, logger, cancellationToken);

    // Step 2: Create perspective tables (generated at build time from discovered PerspectiveRow<TModel> types)
    logger?.LogInformation("Creating perspective tables for {DbContext}...", "__DBCONTEXT_CLASS__");
    await ExecutePerspectiveTablesAsync(dbContext, logger, cancellationToken);

    // Step 3: Add constraints (composite PKs, FKs) that TableDefinition doesn't support yet
    logger?.LogInformation("Adding database constraints for {DbContext}...", "__DBCONTEXT_CLASS__");
    await ExecuteConstraintsAsync(dbContext, logger, cancellationToken);

    // Step 4: Create PostgreSQL functions (process_work_batch, etc.)
    logger?.LogInformation("Creating PostgreSQL functions for {DbContext}...", "__DBCONTEXT_CLASS__");
    await ExecuteMigrationsAsync(dbContext, logger, cancellationToken);

    logger?.LogInformation("Whizbang database initialization complete for {DbContext}", "__DBCONTEXT_CLASS__");
  }

  /// <summary>
  /// Executes core infrastructure table DDL generated at build time.
  /// Creates all Whizbang core tables: Inbox, Outbox, EventStore, ReceptorProcessing,
  /// PerspectiveCheckpoints, RequestResponse, ServiceInstances, PartitionAssignments,
  /// MessageDeduplication, Sequences, and EventSequence.
  /// SQL is generated using PostgresSchemaBuilder.Instance.BuildInfrastructureSchema().
  /// AOT-compatible - SQL is embedded at build time, no dynamic generation.
  /// </summary>
  private static async Task ExecuteCoreInfrastructureTablesAsync(
    __DBCONTEXT_FQN__ dbContext,
    ILogger? logger,
    CancellationToken cancellationToken) {

    // SQL embedded by source generator from CoreInfrastructureSchema.sql resource
    const string CoreInfrastructureSchema = #region CORE_INFRASTRUCTURE_SCHEMA
    // Core infrastructure DDL will be embedded here by the source generator
    #endregion;

    if (string.IsNullOrWhiteSpace(CoreInfrastructureSchema)) {
      logger?.LogWarning("Core infrastructure schema is empty - this should never happen!");
      return;
    }

    try {
      await dbContext.Database.ExecuteSqlRawAsync(CoreInfrastructureSchema, cancellationToken);
      logger?.LogInformation("Core infrastructure tables created successfully");
    } catch (Npgsql.PostgresException ex) when (ex.SqlState == "42P07") {
      // 42P07 = duplicate_table (expected if tables already exist)
      logger?.LogInformation("Core infrastructure tables already exist (expected): {Table}", ex.TableName ?? "unknown");
    } catch (Exception ex) {
      logger?.LogError(ex, "Failed to create core infrastructure tables");
      throw;
    }
  }

  /// <summary>
  /// Executes perspective table DDL generated at build time.
  /// SQL is generated by discovering PerspectiveRow&lt;TModel&gt; types in user code.
  /// Creates tables with schema: stream_id (UUID PK), data (JSONB), version (BIGINT), updated_at (TIMESTAMPTZ).
  /// AOT-compatible - no reflection or dynamic code generation.
  /// </summary>
  private static async Task ExecutePerspectiveTablesAsync(
    __DBCONTEXT_FQN__ dbContext,
    ILogger? logger,
    CancellationToken cancellationToken) {

    // SQL embedded by source generator from discovered PerspectiveRow<TModel> types
    const string PerspectiveTablesSchema = #region PERSPECTIVE_TABLES_SCHEMA
    // Perspective table DDL will be embedded here by the source generator
    #endregion;

    if (string.IsNullOrWhiteSpace(PerspectiveTablesSchema)) {
      logger?.LogInformation("No perspective tables to create (DbContext has no perspectives)");
      return;
    }

    try {
      await dbContext.Database.ExecuteSqlRawAsync(PerspectiveTablesSchema, cancellationToken);
      logger?.LogInformation("Perspective tables created successfully");
    } catch (Npgsql.PostgresException ex) when (ex.SqlState == "42P07") {
      // 42P07 = duplicate_table (expected if tables already exist)
      logger?.LogInformation("Perspective tables already exist (expected): {Table}", ex.TableName ?? "unknown");
    } catch (Exception ex) {
      logger?.LogError(ex, "Failed to create perspective tables");
      throw;
    }
  }

  /// <summary>
  /// Executes constraint DDL for composite primary keys and foreign keys.
  /// These constraints are not yet supported in TableDefinition, so they're added manually.
  /// Includes: composite PK for perspective_checkpoints, FKs to event_store, unique constraints.
  /// </summary>
  private static async Task ExecuteConstraintsAsync(
    __DBCONTEXT_FQN__ dbContext,
    ILogger? logger,
    CancellationToken cancellationToken) {

    const string Constraints = @"
-- Composite PK for perspective_checkpoints (stream_id, perspective_name)
-- First drop the individual PKs created by the schema builder
DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_constraint WHERE conname = 'wh_perspective_checkpoints_pkey') THEN
    ALTER TABLE wh_perspective_checkpoints DROP CONSTRAINT wh_perspective_checkpoints_pkey CASCADE;
  END IF;
END $$;

-- Add composite primary key
ALTER TABLE wh_perspective_checkpoints
  ADD CONSTRAINT pk_perspective_checkpoints PRIMARY KEY (stream_id, perspective_name);

-- Foreign keys (note: PostgreSQL doesn't support IF NOT EXISTS for FK constraints)
DO $$
BEGIN
  -- FK: receptor_processing.event_id -> event_store.event_id
  IF NOT EXISTS (
    SELECT 1 FROM pg_constraint WHERE conname = 'fk_receptor_processing_event'
  ) THEN
    ALTER TABLE wh_receptor_processing
      ADD CONSTRAINT fk_receptor_processing_event
      FOREIGN KEY (event_id) REFERENCES wh_event_store(event_id) ON DELETE CASCADE;
  END IF;

  -- FK: perspective_checkpoints.last_event_id -> event_store.event_id
  IF NOT EXISTS (
    SELECT 1 FROM pg_constraint WHERE conname = 'fk_perspective_checkpoints_event'
  ) THEN
    ALTER TABLE wh_perspective_checkpoints
      ADD CONSTRAINT fk_perspective_checkpoints_event
      FOREIGN KEY (last_event_id) REFERENCES wh_event_store(event_id) ON DELETE RESTRICT;
  END IF;
END $$;

-- Unique constraint for receptor_processing (event_id, receptor_name)
CREATE UNIQUE INDEX IF NOT EXISTS uq_receptor_processing_event_receptor
  ON wh_receptor_processing(event_id, receptor_name);

-- Partial indexes for status-based queries
CREATE INDEX IF NOT EXISTS idx_receptor_processing_status_failed
  ON wh_receptor_processing(status) WHERE (status & 4) = 4; -- Failed flag

CREATE INDEX IF NOT EXISTS idx_perspective_checkpoints_catching_up
  ON wh_perspective_checkpoints(status) WHERE (status & 8) = 8; -- CatchingUp flag

CREATE INDEX IF NOT EXISTS idx_perspective_checkpoints_failed
  ON wh_perspective_checkpoints(status) WHERE (status & 4) = 4; -- Failed flag
";

    try {
      await dbContext.Database.ExecuteSqlRawAsync(Constraints, cancellationToken);
      logger?.LogInformation("Database constraints added successfully");
    } catch (Npgsql.PostgresException ex) {
      // Constraints might already exist - log as information, not error
      logger?.LogInformation("Constraint operation completed (some constraints may already exist): {Message}", ex.MessageText);
    } catch (Exception ex) {
      logger?.LogWarning(ex, "Failed to add some database constraints (constraints may already exist)");
      // Don't throw - constraints might already exist from previous runs
    }
  }

  /// <summary>
  /// Executes PostgreSQL migration scripts to create functions.
  /// Migrations are embedded as string constants for AOT compatibility.
  /// </summary>
  private static async Task ExecuteMigrationsAsync(
    __DBCONTEXT_FQN__ dbContext,
    ILogger? logger,
    CancellationToken cancellationToken) {

    // Migration scripts are embedded below by the source generator
    var migrations = GetMigrationScripts();

    foreach (var (name, sql) in migrations) {
      try {
        logger?.LogInformation("Executing migration: {Migration}", name);
        await dbContext.Database.ExecuteSqlRawAsync(sql, cancellationToken);
        logger?.LogInformation("Migration {Migration} completed successfully", name);
      } catch (Npgsql.PostgresException ex) when (ex.SqlState == "42723") {
        // 42723 = duplicate_function - function already exists, safe to ignore
        logger?.LogInformation("Function already exists (expected): {Message}", ex.MessageText);
      } catch (Exception ex) {
        logger?.LogError(ex, "Failed to execute migration {Migration}", name);
        throw;
      }
    }
  }

  /// <summary>
  /// Returns migration scripts as (name, sql) tuples.
  /// Scripts are embedded by the source generator.
  /// </summary>
  private static (string Name, string Sql)[] GetMigrationScripts() {
    return new[] {
      #region MIGRATIONS
      // Migration scripts will be embedded here by the source generator
      #endregion
    };
  }

}
